{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data point: 150\n",
      "size of attribute: 5\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, median\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Lp norm of two given data\n",
    "def distance(Class1, Class2, p):\n",
    "    sum = 0\n",
    "    size_of_sttribute = len(Class1)\n",
    "    #print(\"in dist(), # of attr:\", size_of_sttribute)\n",
    "    for i in range(size_of_sttribute-1):\n",
    "        sum += math.pow(abs(float(Class1[i])-float(Class2[i])),p)\n",
    "    for i in range(p-1):\n",
    "        #print(\"sqrt once\")\n",
    "        sum = math.sqrt(sum)\n",
    "    return sum\n",
    "\n",
    "def assign(x_input, centroids):\n",
    "    k = len(centroids)\n",
    "    # initial each label as -1\n",
    "    label = [-1]*len(x_input)\n",
    "    for i in range(len(x_input)):\n",
    "        dist = [-1]*k\n",
    "        # calculate the distance to all centroids\n",
    "        for j in range(k):\n",
    "            dist[j] = distance(x_input[i], centroids[j], 2)\n",
    "        # choose the minimum one as the label\n",
    "        label[i] = dist.index(min(dist))\n",
    "    # return list of label\n",
    "    return label\n",
    "\n",
    "# for a given data point, k value, and initial centroids\n",
    "# return the list of label and the final centroids\n",
    "def k_means_cs171(x_input, k, init_centroids):\n",
    "    centroids = init_centroids\n",
    "    cluster_assignments = [-1]*len(x_input)\n",
    "    iter = 0\n",
    "    # first time cluster assign\n",
    "    label = assign(x_input, centroids)\n",
    "    while cluster_assignments != label:\n",
    "        iter +=1\n",
    "        cluster_assignments = label\n",
    "        # clean centroids\n",
    "        # centroids[] to accumulate the attribute of same cluster,\n",
    "        centroids=[ [0] * len(x_input[0]) for i in range(k) ]\n",
    "        # count[] to accumulate of different cluster, initialize as [0,0,0,0,0,...]\n",
    "        count = [0]*k\n",
    "        # update centroids[] and count[]\n",
    "        for i in range(len(label)):\n",
    "            count[label[i]] += 1\n",
    "            for s in range(len(centroids[0])):\n",
    "                centroids[label[i]][s] += float(x_input[i][s])\n",
    "        # calculate the new centroids\n",
    "        for x in range(k):\n",
    "            if count[x] == 0:\n",
    "                count[x] = 1\n",
    "        for i in range(len(centroids)):\n",
    "            for s in range(len(centroids[i])):\n",
    "                centroids[i][s] = centroids[i][s]/count[i]\n",
    "        # update cluster_assignments\n",
    "        label = assign(x_input, centroids)\n",
    "    # print(\"iterator:\",iter)\n",
    "    return cluster_assignments,centroids\n",
    "\n",
    "def sum_of_error2(x_input, cluster_assignments,cluster_centroids):\n",
    "    dist = 0\n",
    "    for i in range(len(x_input)):\n",
    "        # print(cluster_assignments[i])\n",
    "        dist += distance(x_input[i], cluster_centroids[int(cluster_assignments[i]) ], 2)\n",
    "    return dist\n",
    "\n",
    "# see if initial centroids contains dupliate points\n",
    "def check_init(init_centroids, k):\n",
    "    seen = set(tuple(i) for i in init_centroids)\n",
    "    if len(seen) == k:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "fp = open('iris.data', \"r\")\n",
    "index_of_arrtibute = 4\n",
    "attr_target_list =[]\n",
    "init_centroids =[]\n",
    "\n",
    "i=0\n",
    "while True:\n",
    "    data = fp.readline().split(',')\n",
    "    if data[0] == '\\n' or data[0] == '':break\n",
    "    i+=1\n",
    "    context = data[0:4]\n",
    "    label = data[4][:len(data[4])-1]\n",
    "    if label == 'Iris-setosa':\n",
    "        context.append(0)\n",
    "    elif label == 'Iris-versicolor':\n",
    "        context.append(1)\n",
    "    elif label == 'Iris-virginica':\n",
    "        context.append(2)\n",
    "    else:\n",
    "        print(\"in reading file, unexpected label\")\n",
    "    attr_target_list.append(context)\n",
    "#end of read file\n",
    "\n",
    "print(\"size of data point:\",len(attr_target_list))\n",
    "print(\"size of attribute:\",len(attr_target_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 143, 17]\n",
      "init_centroids: [['5.0', '3.2', '1.2', '0.2', 0], ['6.8', '3.2', '5.9', '2.3', 2], ['5.1', '3.5', '1.4', '0.3', 0]]\n",
      "Cluster[ 0 ] Show First 3:\n",
      "0\n",
      "0\n",
      "0\n",
      "Cluster[ 1 ] Show First 3:\n",
      "2\n",
      "2\n",
      "2\n",
      "Cluster[ 2 ] Show First 3:\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "max_iter = [1]\n",
    "for _iter in range(len(max_iter)):\n",
    "    iter = max_iter[_iter] # 2/ 10/ 100\n",
    "    # generate random init_centroids\n",
    "    k=3\n",
    "    # cluster[0]/ cluster[1]/cluster[2] store data point in three cluster respectively\n",
    "    cluster = [[],[],[]]\n",
    "    for m in range(iter):\n",
    "        # generate the k data points randomly\n",
    "        init_cent_index = random.sample(range(len(attr_target_list)), k)\n",
    "        print(init_cent_index)\n",
    "        init_centroids = []\n",
    "        for i in range(k):\n",
    "            init_centroids.append(attr_target_list[init_cent_index[i]])\n",
    "        print(\"init_centroids:\",init_centroids)\n",
    "        # if there is duplicate point, re-initialize\n",
    "        while check_init(init_centroids, k):\n",
    "            init_cent_index = random.sample(range(len(attr_target_list)), k)\n",
    "            init_centroids = []\n",
    "            for i in range(k):\n",
    "                init_centroids.append(attr_target_list[init_cent_index[i]])\n",
    "        # use the init_centroids to do k-means\n",
    "        cluster_assignments,cluster_centroids = k_means_cs171(attr_target_list, k, init_centroids)\n",
    "        # print(cluster_assignments)\n",
    "        # print(cluster_centroids)\n",
    "\n",
    "        # depending on the label we assign, insert them into cluster[0]/ cluster[1]/cluster[2]\n",
    "        for i in range(len(cluster_assignments)):\n",
    "            c = cluster_assignments[i]\n",
    "            cluster[c].append(attr_target_list[i])\n",
    "        # check the top 3 point in cluster[0]/ cluster[1]/cluster[2]\n",
    "        for i in range(len(cluster)):\n",
    "            dist = [0]*len(cluster[i])\n",
    "            for j in range(len(cluster[i])):\n",
    "                dist[j] = distance(cluster[i][j], cluster_centroids[i], 2)\n",
    "            # print(\"dist \",i,\" = \",dist)\n",
    "            index = sorted(range(len(dist)), key=lambda _k: dist[_k])\n",
    "            print(\"Cluster[\",i,\"] Show First 3:\")\n",
    "            for m in range(3):\n",
    "                    print(cluster[i][index[m]][4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
